<!doctype html>
<html lang="en">

<head>
   <meta charset="utf-8">
   <link href="./styles/bootstrap.min.css" rel="stylesheet" type="text/css">
   <style>
      @import url(https://fonts.googleapis.com/css?family=Lato:300italic,700italic,300,700);

      body {
         font-family: 'Lato';
         background-color: #f0f0f0;
         margin: 0px auto;
         max-width: 1150px;
      }

      #overlay {
         position: absolute;
         top: 0px;
         left: 0px;
         -o-transform: scaleX(-1);
         -webkit-transform: scaleX(-1);
         transform: scaleX(-1);
         -ms-filter: fliph;
         /*IE*/
         filter: fliph;
         /*IE*/
         opacity: 0.5
      }

      #videoel {
         -o-transform: scaleX(-1);
         -webkit-transform: scaleX(-1);
         transform: scaleX(-1);
         -ms-filter: fliph;
         /*IE*/
         filter: fliph;
         /*IE*/
         opacity: 0.2
      }

      #container {
         position: relative;
         width: 370px;
         /*margin : 0px auto;*/
      }

      #content {
         margin-top: 50px;
         margin-left: auto;
         margin-right: auto;
         max-width: 600px;
      }

      h2 {
         font-weight: 400;
      }

      #emotion_container {
         width: 600px;
      }

      #emotion_icons {
         height: 50px;
         padding-left: 40px;
      }

      .emotion_icon {
         width: 40px;
         height: 40px;
         margin-top: 5px;
         /*margin-left : 13px;*/
         margin-left: 35px;
      }

      #icon1,
      #icon2,
      #icon3,
      #icon4,
      #icon5,
      #icon6 {
         visibility: hidden;
      }
   </style>
   <script>
      // getUserMedia only works over https in Chrome 47+, so we redirect to https. Also notify user if running from file.
      if (window.location.protocol == "file:") {
         alert("You seem to be running this example directly from a file. Note that these examples only work when served from a server or localhost due to canvas cross-domain restrictions.");
      } else if (window.location.hostname !== "localhost" && window.location.protocol !== "https:") {
         window.location.protocol = "https";
      }
   </script>
</head>

<body id="clm-emotion">
   <script src="./js/utils.js"></script>
   <script src="./js/clmtrackr.min.js"></script>
   <script src="./js/model_pca_20_svm.js"></script>
   <script src="./js/emotion_classifier.js"></script>
   <script src="./js/emotionmodel.js"></script>
   <div id="content">
      <h2>Emotion Detection</h2>
      <div id="container">
         <video id="videoel" width="400" height="300" preload="auto" loop playsinline autoplay>
         </video>
         <canvas id="overlay" width="400" height="300"></canvas>
      </div>
      <div id="emotion_container">
         <div id="emotion_icons">
            <img class="emotion_icon" id="icon1" src="./media/icon_angry.png">
            <img class="emotion_icon" id="icon2" src="./media/icon_sad.png">
            <img class="emotion_icon" id="icon3" src="./media/icon_surprised.png">
            <img class="emotion_icon" id="icon4" src="./media/icon_happy.png">
         </div>
         <div id='emotion_chart'></div>
      </div>

      <script>
         var vid = document.getElementById('videoel');
         var vid_width = vid.width;
         var vid_height = vid.height;
         var overlay = document.getElementById('overlay');
         var overlayCC = overlay.getContext('2d');

         /********** check and set up video/webcam **********/

         function adjustVideoProportions() {
            // resize overlay and video if proportions are different
            // keep same height, just change width
            var proportion = vid.videoWidth / vid.videoHeight;
            vid_width = Math.round(vid_height * proportion);
            vid.width = vid_width;
            overlay.width = vid_width;
         }

         function gumSuccess(stream) {
            // add camera stream if getUserMedia succeeded
            if ("srcObject" in vid) {
               vid.srcObject = stream;
            } else {
               vid.src = (window.URL && window.URL.createObjectURL(stream));
            }
            vid.onloadedmetadata = function () {
               adjustVideoProportions();
               vid.play();
            }
            vid.onresize = function () {
               adjustVideoProportions();
               if (trackingStarted) {
                  ctrack.stop();
                  ctrack.reset();
                  ctrack.start(vid);
               }
            }
         }

         function gumFail() {
            alert("There was some problem trying to fetch video from your webcam. If you have a webcam, please make sure to accept when the browser asks for access to your webcam.");
         }

         navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;
         window.URL = window.URL || window.webkitURL || window.msURL || window.mozURL;

         // check for camerasupport
         if (navigator.mediaDevices) {
            navigator.mediaDevices.getUserMedia({ video: true }).then(gumSuccess).catch(gumFail);
         } else if (navigator.getUserMedia) {
            navigator.getUserMedia({ video: true }, gumSuccess, gumFail);
         } else {
            alert("This demo depends on getUserMedia, which your browser does not seem to support. :(");
         }

         vid.addEventListener('canplay', startEmotionListener, false);

         /*********** setup of emotion detection *************/

         // set eigenvector 9 and 11 to not be regularized. This is to better detect motion of the eyebrows
         pModel.shapeModel.nonRegularizedVectors.push(9);
         pModel.shapeModel.nonRegularizedVectors.push(11);

         var ctrack = new clm.tracker({ useWebGL: true });
         ctrack.init(pModel);
         var trackingStarted = false;

         var startEmotionListener = function () {
            let eToggle = 0
            function _initWatcher(event) {
               const key = String.fromCharCode(event.keyCode).toLowerCase()
               if (key === 'e' && eToggle < 1) {
                  startVideo()
                  eToggle++;
               }
            }

            function _resetWatcher(event) {
               eToggle = 0
               stopVideo()
               var cp = ctrack.getCurrentParameters();
               var finalVal = ec.meanPredict(cp)
               console.log('DESIRED VALUE', finalVal)
            }

            var charElement = document.getElementById("clm-emotion");
            charElement.addEventListener('keydown', _initWatcher, false);
            charElement.addEventListener('keyup', _resetWatcher, false);
         }

         function stopVideo() {
            ctrack.stop();
            trackingStarted = false;
         }

         window.addEventListener("load", startEmotionListener, false);

         function startVideo() {
            // start video
            vid.play();
            // start tracking
            ctrack.reset();
            ctrack.start(vid);
            trackingStarted = true;
            // start loop to draw face
            drawLoop();
         }

         function drawLoop() {
            if (trackingStarted) {
               requestAnimFrame(drawLoop);
               overlayCC.clearRect(0, 0, vid_width, vid_height);
               //psrElement.innerHTML = "score :" + ctrack.getScore().toFixed(4);
               if (ctrack.getCurrentPosition()) {
                  ctrack.draw(overlay);
               }
               var cp = ctrack.getCurrentParameters();

               var er = ec.meanPredict(cp);
               console.log("EMOTION LEVEL", er)
               if (er) {
                  for (var i = 0; i < er.length; i++) {
                     if (er[i].value > 0.4) {
                        document.getElementById('icon' + (i + 1)).style.visibility = 'visible';
                     } else {
                        document.getElementById('icon' + (i + 1)).style.visibility = 'hidden';
                     }
                  }
               }
            }
         }

         delete emotionModel['disgusted'];
         delete emotionModel['fear'];
         var ec = new emotionClassifier();
         ec.init(emotionModel);
         var emotionData = ec.getBlank();
    
      </script>
   </div>
</body>

</html>